\section{Related Works}\label{sec:relatedModel}
To ease the development and analysis of parallel programs, the BSP programming model has been implemented as API libraries~\citep{BSPLib}, and recently enhanced to simplify programming on GPU architectures~\citep{bsgp}. These developments help to create scientific applications in massively parallel environments computing in an easier and better way.

In  recent  years,  studies on GPU performance using analytical modeling have appeared, most of them have also used NVIDIA cards in their experiments. \cite{GpuModelHong:2009} have proposed and evaluated a memory and parallelism-aware analytic model to estimate execution time of massively parallel application in GPUs. The key idea is to find a metric which they have called MWP (Memory Warp Parallelism) and CWP (Compute Warp Parallelism). The analytic model provides good performance predictions, however, this model requires a deep analysis and understanding by third-party developers of parallel applications in CUDA. They have introduced the metrics MWP and CWP, MWP is related to how much memory parallelism in the application and CWP is related to the program characteristics. CWP is used to decide whether performance is dominated by computation or communication. 

~\cite{PredicModelGPU2009} have presented a combination of known models with small extensions. The models they have used are: BSP model, PRAM model by~\citep{Fortune:1978:PRAM} and the QRQW model by~\cite{Gibbons1983:QRQW}. The authors abstract the GPU computational model by considering the pipeline characteristic of the application in GPU architectures. But they do not describe how divergence can impact in the efficiency of GPU applications. 

~\cite{Zhang:2011:GPUmodel} have presented a quantitative performance analysis model, based on micro-benchmarks for NVIDIA GeForce 200-series GPUs. They have developed a throughput model for three components of GPU execution time: the instruction pipeline, shared memory access, and global memory access. The model is based on a native GPU instruction set instead of the intermediate PTX assembly language or a high-level language. Our model uses a high-level bridging model for parallel computation and is focused on computation and communication processes for any GPU application. This encourage developers to use better optimizations in communication and computation.

~\cite{Kerr:2012:Eiger} developed a methodology for the systematic construction of performance models of heterogeneous processors. This methodology is comprised of experimental data acquisition and database construction, a series of data analysis passes over the database, and model selection and construction. They developed a framework, named Eiger, that implements their methodology. Another framework to construct performance models was presented by~\cite{Spafford:2012:Aspen}. They used a domain specific language to develop analytical performance models for the three dimensional Fast Fourier Transform (3D FFT).  

Our model is based solely in the BSP model. Scalability, optimization effects, divergence and differences between architectures are all adjusted by a single parameter $\lambda$. Profiling techniques were used to confirm information about caches memories accesses and to establish parameters about computation and communication when this parameters were difficult to find in the source code of the kernels. This model allows an easy parametrization, well-suited for many CUDA kernels in productions.
\todoMT{Compare between both related works sections}
