Denise - 15:10
Primeira parte está melhor escrita
Precisa de mais revisão de português
Fundamentos demais?
Parte da GPU um pouco longa demais?
Sintetizar mais na tese.
Threads vs Linhas de execução. Uniformizar os termos (não só esses).
Achou que você estivesse usando o google translator...
Cuidado com o "previsto" e "medido"
Confusão entre blocos, threads, no experimentos com matriz cuidado...
** ficou de ruim essa parte **
O que você espera da aplicação do modelo assim que estiver validado?
Deixar claro que é necessária ao menos uma execução para estimar \lambda
Muito legal o trabalho ,ainda mais se pensar na aplicação disso.
Parabéns
11:49 Gubi
As vezes o texto não fica muito claro.
Detalhe: Coloca no começo que a HPC começam a aparecer simultameamente, mas começou antes.
Cuidado MIMD.
GPU não é só para a área científica.
Tem além do OpenCL e o Cuda mais uns que eu não ouvi
Algo na página 17, definição de WARP.
Pegar o trabalho do Paulo (?)
Resultados preliminares: relação entre os parâmetros confusa.
Adoção de linhas por bloco, parece escolha arbitrária. Falar mais como foi
planejado o experimento.
Algo na página 30 (parece que na definição da subsequencia máxima)
Primeiro modelo, pode melhorar pegando o teto da divisão.
Média de 10....
Pag 34. coisinha de português, última parágrafo antes de 3.1.3.
Lambda, é um ajuste. Por que é linear? É uma conjectura forte, discutir mais.
Relacionar com característica de hardware.
Pag 35. antes de falar do segundo modelo, afirmação forte. Muitas aplicações???
Adequada???
** Ficou ruim, parei de ouvir :( **
Principal crítica aprimorar o lambda.
Sanduíche, com IA, não, mas reconhecimento de padrões.




